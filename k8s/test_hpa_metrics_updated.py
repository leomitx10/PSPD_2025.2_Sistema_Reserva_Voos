#!/usr/bin/env python3
"""
Script para verificar se as m√©tricas de HPA est√£o dispon√≠veis no Prometheus
"""
import requests
import json
from datetime import datetime

# Configura√ß√£o
PROMETHEUS_URL = "http://localhost:9090"

def query_prometheus(query):
    """Executa uma query no Prometheus"""
    try:
        response = requests.get(
            f"{PROMETHEUS_URL}/api/v1/query",
            params={'query': query},
            timeout=10
        )
        if response.status_code == 200:
            data = response.json()
            if data['status'] == 'success':
                return data['data']['result']
        return None
    except Exception as e:
        print(f"‚ùå Erro ao consultar Prometheus: {e}")
        return None

def check_metric(name, query, description):
    """Verifica se uma m√©trica est√° dispon√≠vel"""
    print(f"\nüîç Verificando: {name}")
    print(f"   {description}")
    
    result = query_prometheus(query)
    
    if result is None:
        print(f"   ‚ùå Erro ao executar query")
        return False
    elif len(result) == 0:
        print(f"   ‚ö†Ô∏è  Nenhum dado encontrado")
        return False
    else:
        print(f"   ‚úÖ Dados dispon√≠veis ({len(result)} m√©tricas)")
        for metric in result[:3]:  # Mostra at√© 3 exemplos
            labels = metric.get('metric', {})
            value = metric.get('value', [None, None])[1]
            
            # Formatar labels
            label_str = ', '.join([f"{k}={v}" for k, v in labels.items() if k != '__name__'])
            print(f"      ‚Ä¢ {label_str[:80]}: {value}")
        
        if len(result) > 3:
            print(f"      ... e mais {len(result) - 3} m√©tricas")
        return True

def main():
    print("=" * 70)
    print("Verifica√ß√£o de M√©tricas de HPA no Prometheus")
    print("=" * 70)
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Prometheus URL: {PROMETHEUS_URL}")
    
    # Verificar conectividade com Prometheus
    print("\nüì° Verificando conectividade com Prometheus...")
    try:
        response = requests.get(f"{PROMETHEUS_URL}/-/healthy", timeout=5)
        if response.status_code == 200:
            print("   ‚úÖ Prometheus est√° acess√≠vel")
        else:
            print(f"   ‚ùå Prometheus retornou status {response.status_code}")
            print("   üí° Execute: kubectl port-forward -n monitoring svc/prometheus 9090:9090")
            return
    except Exception as e:
        print(f"   ‚ùå N√£o foi poss√≠vel conectar ao Prometheus: {e}")
        print("   üí° Execute: kubectl port-forward -n monitoring svc/prometheus 9090:9090")
        return
    
    metrics_ok = 0
    metrics_total = 0
    
    # M√©tricas Essenciais do HPA
    print("\n" + "=" * 70)
    print("üìä M√âTRICAS ESSENCIAIS DO HPA")
    print("=" * 70)
    
    metrics_total += 1
    if check_metric(
        "CPU Target Utilization",
        'kube_horizontalpodautoscaler_spec_target_metric{metric_name="cpu", metric_target_type="utilization"}',
        "Threshold de CPU configurado no HPA (deveria ser 50%)"
    ):
        metrics_ok += 1
    
    metrics_total += 1
    if check_metric(
        "R√©plicas Desejadas",
        'kube_horizontalpodautoscaler_status_desired_replicas',
        "N√∫mero de r√©plicas que o HPA quer ter"
    ):
        metrics_ok += 1
    
    metrics_total += 1
    if check_metric(
        "R√©plicas Atuais",
        'kube_horizontalpodautoscaler_status_current_replicas',
        "N√∫mero de r√©plicas atualmente rodando"
    ):
        metrics_ok += 1
    
    metrics_total += 1
    if check_metric(
        "Min/Max R√©plicas",
        'kube_horizontalpodautoscaler_spec_min_replicas',
        "Configura√ß√£o de r√©plicas m√≠nimas"
    ):
        metrics_ok += 1
    
    # M√©tricas de CPU e Mem√≥ria
    print("\n" + "=" * 70)
    print("üíª M√âTRICAS DE CPU E MEM√ìRIA")
    print("=" * 70)
    
    metrics_total += 1
    if check_metric(
        "Uso de CPU por Pod",
        'sum(rate(container_cpu_usage_seconds_total{pod=~"voos-service.*|hoteis-service.*|api-gateway.*", container!="POD"}[5m])) by (pod) * 1000',
        "CPU utilizada por cada pod (millicores)"
    ):
        metrics_ok += 1
    
    metrics_total += 1
    if check_metric(
        "CPU Request por Pod",
        'sum(kube_pod_container_resource_requests{resource="cpu", pod=~"voos-service.*|hoteis-service.*|api-gateway.*"}) by (pod)',
        "CPU solicitada (request) por pod"
    ):
        metrics_ok += 1
    
    metrics_total += 1
    if check_metric(
        "% CPU Usado vs Request",
        '100 * sum(rate(container_cpu_usage_seconds_total{pod=~"voos-service.*|hoteis-service.*|api-gateway.*", container!="POD"}[5m])) by (pod) / sum(kube_pod_container_resource_requests{resource="cpu", pod=~"voos-service.*|hoteis-service.*|api-gateway.*"}) by (pod)',
        "Percentual de CPU usado em rela√ß√£o ao request"
    ):
        metrics_ok += 1
    
    metrics_total += 1
    if check_metric(
        "Uso de Mem√≥ria por Pod",
        'sum(container_memory_working_set_bytes{pod=~"voos-service.*|hoteis-service.*|api-gateway.*", container!="POD"}) by (pod)',
        "Mem√≥ria utilizada por cada pod"
    ):
        metrics_ok += 1
    
    # M√©tricas de Elasticidade
    print("\n" + "=" * 70)
    print("üìà M√âTRICAS DE ELASTICIDADE")
    print("=" * 70)
    
    metrics_total += 1
    if check_metric(
        "N√∫mero de R√©plicas por Deployment",
        'kube_deployment_status_replicas{deployment=~"voos-service|hoteis-service|api-gateway"}',
        "R√©plicas atuais de cada deployment"
    ):
        metrics_ok += 1
    
    metrics_total += 1
    if check_metric(
        "HPA Able to Scale",
        'kube_horizontalpodautoscaler_status_condition{condition="AbleToScale"}',
        "Se o HPA consegue escalar (1 = sim, 0 = n√£o)"
    ):
        metrics_ok += 1
    
    metrics_total += 1
    if check_metric(
        "HPA Scaling Active",
        'kube_horizontalpodautoscaler_status_condition{condition="ScalingActive"}',
        "Se o escalamento est√° ativo (1 = sim, 0 = n√£o)"
    ):
        metrics_ok += 1
    
    metrics_total += 1
    if check_metric(
        "Diferen√ßa Desejado vs Atual",
        'kube_horizontalpodautoscaler_status_desired_replicas - kube_horizontalpodautoscaler_status_current_replicas',
        "Diferen√ßa entre r√©plicas desejadas e atuais (>0 = escalando)"
    ):
        metrics_ok += 1
    
    # Resumo
    print("\n" + "=" * 70)
    print("üìä RESUMO")
    print("=" * 70)
    print(f"M√©tricas verificadas: {metrics_total}")
    print(f"M√©tricas dispon√≠veis: {metrics_ok}")
    print(f"M√©tricas ausentes: {metrics_total - metrics_ok}")
    
    percentage = (metrics_ok / metrics_total) * 100 if metrics_total > 0 else 0
    
    print(f"\nTaxa de sucesso: {percentage:.1f}%")
    
    if percentage == 100:
        print("\n‚úÖ TODAS AS M√âTRICAS EST√ÉO DISPON√çVEIS!")
        print("   O sistema est√° pronto para validar elasticidade.")
    elif percentage >= 75:
        print("\n‚ö†Ô∏è  A MAIORIA DAS M√âTRICAS EST√Å DISPON√çVEL")
        print("   O sistema pode validar elasticidade, mas algumas m√©tricas est√£o faltando.")
    else:
        print("\n‚ùå MUITAS M√âTRICAS EST√ÉO FALTANDO")
        print("   Verifique a configura√ß√£o do Prometheus e do kube-state-metrics.")
        print("\nüí° Passos para corrigir:")
        print("   1. Aplicar a configura√ß√£o atualizada do Prometheus:")
        print("      kubectl apply -f prometheus-config.yaml")
        print("   2. Reiniciar o Prometheus:")
        print("      kubectl rollout restart deployment/prometheus -n monitoring")
        print("   3. Verificar se kube-state-metrics est√° rodando:")
        print("      kubectl get pods -n monitoring -l app=kube-state-metrics")
    
    print("\n" + "=" * 70)

if __name__ == "__main__":
    main()
